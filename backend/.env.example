# =============================================================================
# Backend Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
# =============================================================================

# -----------------------------------------------------------------------------
# Cohere API (Embeddings)
# -----------------------------------------------------------------------------
# Get your API key from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=your-cohere-api-key-here

# Cohere embedding model (embed-english-v3.0 produces 1024-dim vectors)
COHERE_EMBEDDING_MODEL=embed-english-v3.0

# -----------------------------------------------------------------------------
# Gemini API (Google AI) - for text generation
# -----------------------------------------------------------------------------
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# -----------------------------------------------------------------------------
# Embedding Provider Selection
# -----------------------------------------------------------------------------
# Choose which provider to use for embeddings: "cohere" or "gemini"
# Cohere: embed-english-v3.0 (1024-dim) - better for semantic search
# Gemini: text-embedding-004 (768-dim) - alternative option
EMBEDDING_PROVIDER=cohere

# -----------------------------------------------------------------------------
# Qdrant Cloud (Vector Database)
# -----------------------------------------------------------------------------
# Get your credentials from: https://cloud.qdrant.io/
QDRANT_URL=https://your-cluster-id.qdrant.cloud:6333
QDRANT_API_KEY=your-qdrant-api-key-here
QDRANT_COLLECTION=textbook_chunks

# -----------------------------------------------------------------------------
# Database (Neon PostgreSQL)
# -----------------------------------------------------------------------------
# Get your connection string from: https://console.neon.tech/
# Format: postgresql://user:password@host/database?sslmode=require

# SQLite (development - default):
# DATABASE_URL=sqlite:///./app.db

# Neon PostgreSQL (production):
DATABASE_URL=postgresql://user:password@ep-xxx.us-east-2.aws.neon.tech/robotics_textbook?sslmode=require

# -----------------------------------------------------------------------------
# Authentication (BetterAuth)
# -----------------------------------------------------------------------------
# Generate a secure secret: python -c "import secrets; print(secrets.token_hex(32))"
BETTER_AUTH_SECRET=your-secret-key-minimum-32-characters-long
BETTER_AUTH_URL=http://localhost:8000

# Session configuration
SESSION_EXPIRE_MINUTES=1440

# -----------------------------------------------------------------------------
# Email Configuration (for verification emails)
# -----------------------------------------------------------------------------
# Using Resend (https://resend.com/) or similar service
EMAIL_API_KEY=your-email-api-key-here
EMAIL_FROM=noreply@yourdomain.com

# For development, you can use console backend (prints to stdout)
# EMAIL_BACKEND=console

# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# Frontend URL for CORS (comma-separated for multiple origins)
FRONTEND_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
# Environment: development, staging, production
ENVIRONMENT=development

# Debug mode (disable in production)
DEBUG=true

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# -----------------------------------------------------------------------------
# RAG Configuration
# -----------------------------------------------------------------------------
# Number of chunks to retrieve for context
RAG_TOP_K=5

# Gemini generation model (used for RAG answer generation)
GENERATION_MODEL=gemini-1.5-flash

# Temperature for generation (0 = deterministic)
GENERATION_TEMPERATURE=0

# Legacy: Gemini embedding model (if using gemini for embeddings)
EMBEDDING_MODEL=text-embedding-004
